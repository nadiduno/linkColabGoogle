{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "analise-de-churn.ipynb",
      "authorship_tag": "ABX9TyMWHPPcD6JX1qy0+X9cYGh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadiduno/linkColabGoogle/blob/main/analise_de_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código fornece uma abordagem básica para análise de churn em dados de um hospital, incluindo a geração de dados fictícios, pré-processamento dos dados, treinamento de um modelo de classificação e avaliação do desempenho do modelo.\n",
        "\n",
        "**Explicação do Código:**\n",
        "- O código começa gerando dados fictícios para um hospital, incluindo idade, sexo, número de consultas, número de exames, valor da fatura e churn (se o cliente deixou de utilizar o serviço).\n",
        "- Em seguida, os dados são divididos em features (X) e target (y), e em conjunto de treinamento e teste.\n",
        "- As features são pré-processadas usando `StandardScaler` para as features numéricas e `OneHotEncoder` para as features categóricas.\n",
        "- Um modelo de classificação `RandomForestClassifier` é treinado com 100 estimadores.\n",
        "- O desempenho do modelo é avaliado usando o relatório de classificação e a matriz de confusão.\n",
        "- Finalmente, a importância das features é calculada e exibida.\n",
        "\n",
        "**Explicação do resultado:**\n",
        "\n",
        "**Relatório de Classificação:**\n",
        "- Precision: A precisão é a proporção de verdadeiros positivos (casos positivos corretamente identificados) em relação a todos os casos positivos previstos pelo modelo. No caso da classe 0 (clientes que não churn), a precisão é 0.80, o que significa que 80% dos casos previstos como não churn foram corretos. Para a classe 1 (clientes que churn), a precisão é 0.00, o que significa que nenhum caso previsto como churn foi correto.\n",
        "- Recall: O recall (ou sensibilidade) é a proporção de verdadeiros positivos em relação a todos os casos positivos reais. No caso da classe 0, o recall é 0.98, o que significa que o modelo identificou corretamente 98% dos casos de clientes que não churn. Para a classe 1, o recall é 0.00, o que significa que o modelo não identificou corretamente nenhum dos casos de clientes que churn.\n",
        "- F1-score: O F1-score é uma média harmônica da precisão e do recall e é útil quando há um desequilíbrio de classes. Ele fornece uma única métrica que combina precisão e recall. No caso da classe 0, o F1-score é 0.88. Para a classe 1, o F1-score é 0.00.\n",
        "- Support: O suporte é o número de ocorrências de cada classe no conjunto de teste.\n",
        "\n",
        "**Matriz de Confusão:**\n",
        "- A matriz de confusão mostra as classificações corretas e incorretas feitas pelo modelo. No caso da matriz de confusão fornecida, temos:\n",
        "   - 158 verdadeiros negativos (TN): clientes que não churn, classificados corretamente como não churn.\n",
        "   - 3 falsos positivos (FP): clientes que não churn, classificados incorretamente como churn.\n",
        "   - 0 verdadeiros positivos (TP): clientes que churn, classificados corretamente como churn.\n",
        "   - 39 falsos negativos (FN): clientes que churn, classificados incorretamente como não churn.\n",
        "\n",
        "**Importância das Features:**\n",
        "- A importância das features mostra a contribuição relativa de cada feature para a capacidade de prever o churn dos clientes. No caso fornecido, as features mais importantes são 'Valor da fatura', 'Idade' e 'Número de consultas', enquanto 'Sexo' tem uma importância relativamente baixa.\n"
      ],
      "metadata": {
        "id": "7SOBw2nXoUt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Gerar dados fictícios do hospital\n",
        "import numpy as np\n",
        "\n",
        "# Definir número de pacientes\n",
        "num_pacientes = 1000\n",
        "\n",
        "# Criar dados fictícios\n",
        "np.random.seed(42)\n",
        "idade = np.random.randint(18, 90, num_pacientes)\n",
        "sexo = np.random.choice(['Masculino', 'Feminino'], num_pacientes)\n",
        "num_consultas = np.random.randint(1, 10, num_pacientes)\n",
        "num_exames = np.random.randint(1, 5, num_pacientes)\n",
        "valor_fatura = np.random.randint(100, 10000, num_pacientes)\n",
        "churn = np.random.choice([0, 1], num_pacientes, p=[0.8, 0.2])\n",
        "\n",
        "# Criar DataFrame\n",
        "dados_hospital = pd.DataFrame({\n",
        "    'Idade': idade,\n",
        "    'Sexo': sexo,\n",
        "    'Número de consultas': num_consultas,\n",
        "    'Número de exames': num_exames,\n",
        "    'Valor da fatura': valor_fatura,\n",
        "    'Churn': churn\n",
        "})\n",
        "\n",
        "# Salvar DataFrame em um arquivo CSV\n",
        "dados_hospital.to_csv('dados_hospital.csv', index=False)\n",
        "\n",
        "# Carregar os dados do hospital\n",
        "dados_hospital = pd.read_csv('dados_hospital.csv')\n",
        "\n",
        "# Dividir os dados em features (variáveis independentes) e target (variável dependente)\n",
        "X = dados_hospital.drop('Churn', axis=1)\n",
        "y = dados_hospital['Churn']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e conjunto de teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento das features\n",
        "numeric_features = ['Idade', 'Número de consultas', 'Número de exames', 'Valor da fatura']\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "categorical_features = ['Sexo']\n",
        "categorical_transformer = OneHotEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Treinar um modelo de classificação (Random Forest)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o desempenho do modelo\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Identificar as features mais importantes para o modelo\n",
        "feature_names = numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "importances = model.feature_importances_\n",
        "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
        "print(\"\\nImportância das Features:\")\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaWv-vX3nUNc",
        "outputId": "213b44ba-8896-402c-ac52-638e64cd810f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.98      0.88       161\n",
            "           1       0.00      0.00      0.00        39\n",
            "\n",
            "    accuracy                           0.79       200\n",
            "   macro avg       0.40      0.49      0.44       200\n",
            "weighted avg       0.65      0.79      0.71       200\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[158   3]\n",
            " [ 39   0]]\n",
            "\n",
            "Importância das Features:\n",
            "               feature  importance\n",
            "3      Valor da fatura    0.400081\n",
            "0                Idade    0.311983\n",
            "1  Número de consultas    0.167248\n",
            "2     Número de exames    0.084492\n",
            "4        Sexo_Feminino    0.019095\n",
            "5       Sexo_Masculino    0.017100\n"
          ]
        }
      ]
    }
  ]
}